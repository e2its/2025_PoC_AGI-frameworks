{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PoC: WeCookio multiagent Strands Agents\n",
    "\n",
    "This notebook demonstrates the WeCookio CrewAI implementation with cost-optimized model selection using uv package manager."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process.Sequential without delegation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Required Packages with uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages using uv\n",
    "!uv add ipykernel strands-agents==1.2.0 strands-agents-tools boto3 botocore pyyaml ipywidgets prompt-template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import logging\n",
    "from strands import Agent\n",
    "from strands.multiagent import Swarm\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "\n",
    "# Enable debug logs and print them to stderr\n",
    "logging.getLogger(\"strands.multiagent\").setLevel(logging.DEBUG)\n",
    "logging.basicConfig(\n",
    "    format=\"%(levelname)s | %(name)s | %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading AWS Enviroment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "AWS_ACCESS_KEY_ID=os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY=os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "AWS_DEFAULT_REGION=os.getenv(\"AWS_REGION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Configuration Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check base folder for relative paths\n",
    "import os\n",
    "print (os.getcwd())\n",
    "prefix = \"strands/latest/\"\n",
    "# Load the integration configuration\n",
    "with open(prefix+'config/integration_config.yaml', 'r') as file:\n",
    "    integration_config = yaml.safe_load(file)\n",
    "# Load the crew configuration\n",
    "with open(prefix+'config/config.yaml', 'r') as file:\n",
    "    strand_config = yaml.safe_load(file)\n",
    "with open(prefix+'config/agents-sequential.yaml', 'r') as file:\n",
    "    agents_config = yaml.safe_load(file)\n",
    "with open(prefix+'config/tasks-sequential.yaml', 'r') as file:\n",
    "    tasks_config = yaml.safe_load(file)\n",
    "\n",
    "print(\"Configuration files loaded successfully!\")\n",
    "print(f\"Integration config keys: {list(integration_config.keys())}\")\n",
    "print(f\"Crew Orchestration keys: {list(strand_config.keys())}\")\n",
    "print(f\"Agents config keys: {list(agents_config.keys())}\")\n",
    "print(f\"Tasks config keys: {list(tasks_config.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model Selection based on complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model_for_complexity(complexity, integration_config):\n",
    "    \"\"\"Select the appropriate model based on task complexity\"\"\"\n",
    "    try:\n",
    "        complexity = complexity + \"_model\"\n",
    "        return integration_config[\"aws_bedrock\"][complexity]\n",
    "    except KeyError:\n",
    "        raise ValueError(f\"Invalid complexity level: {complexity}\")\n",
    "\n",
    "# Example usage\n",
    "high_complexity_model = select_model_for_complexity(\"high_complexity\", integration_config)\n",
    "medium_complexity_model = select_model_for_complexity(\"medium_complexity\", integration_config)\n",
    "low_complexity_model = select_model_for_complexity(\"low_complexity\", integration_config)\n",
    "ultra_low_complexity_model = select_model_for_complexity(\"ultra_low_complexity\", integration_config)\n",
    "\n",
    "print(f\"High complexity model: {high_complexity_model['model_id']}\")\n",
    "print(f\"Medium complexity model: {medium_complexity_model['model_id']}\")\n",
    "print(f\"Low complexity model: {low_complexity_model['model_id']}\")\n",
    "print(f\"Ultra-Low complexity model: {ultra_low_complexity_model['model_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Agents with Model-Specific Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "import boto3\n",
    "from strands.models import BedrockModel\n",
    "from prompt_template import PromptTemplate, InvalidTemplateKeysError, MissingTemplateValuesError, TemplateSerializationError\n",
    "\n",
    "# Global metrics storage\n",
    "execution_metrics = {\n",
    "    'start_time': None,\n",
    "    'total_tokens': 0,\n",
    "    'total_cost': 0.0,\n",
    "    'cycle_durations': [],\n",
    "    'tool_usage': {},\n",
    "    'errors': [],\n",
    "    'agent_performance': {}\n",
    "}\n",
    "\n",
    "def safe_get_metrics(kwargs):\n",
    "    \"\"\"Safely extract metrics from kwargs\"\"\"\n",
    "    try:\n",
    "        metrics = kwargs.get('metrics')\n",
    "        if metrics is None:\n",
    "            return {\n",
    "                'accumulated_usage': {'totalTokens': 0},\n",
    "                'cycle_durations': [],\n",
    "                'tool_metrics': {}\n",
    "            }\n",
    "        return metrics\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Warning: Could not extract metrics: {e}\")\n",
    "        return {\n",
    "            'accumulated_usage': {'totalTokens': 0},\n",
    "            'cycle_durations': [],\n",
    "            'tool_metrics': {}\n",
    "        }\n",
    "\n",
    "def event_loop_tracker(**kwargs):\n",
    "    \"\"\"Enhanced event loop tracker with proper error handling and metrics collection\"\"\"\n",
    "    try:\n",
    "        # Track event loop lifecycle\n",
    "        if kwargs.get(\"init_event_loop\", False):\n",
    "            print(\"ðŸ”„ Event loop initialized\")\n",
    "            execution_metrics['start_time'] = datetime.now()\n",
    "        elif kwargs.get(\"start_event_loop\", False):\n",
    "            print(\"â–¶ï¸ Event loop cycle starting\")\n",
    "        elif kwargs.get(\"start\", False):\n",
    "            print(\"ðŸ“ New cycle started\")\n",
    "        elif \"message\" in kwargs:\n",
    "            print(f\"ðŸ“¬ New message created: {kwargs['message']['role']}\")\n",
    "        elif kwargs.get(\"complete\", False):\n",
    "            print(\"âœ… Cycle completed\")\n",
    "            # Update global metrics\n",
    "            metrics = safe_get_metrics(kwargs)\n",
    "            if metrics['cycle_durations']:\n",
    "                execution_metrics['cycle_durations'].extend(metrics['cycle_durations'])\n",
    "            if metrics['accumulated_usage']['totalTokens']:\n",
    "                execution_metrics['total_tokens'] += metrics['accumulated_usage']['totalTokens']\n",
    "        elif kwargs.get(\"force_stop\", False):\n",
    "            print(f\"ðŸ›‘ Event loop force-stopped: {kwargs.get('force_stop_reason', 'unknown reason')}\")\n",
    "            execution_metrics['errors'].append({\n",
    "                'type': 'force_stop',\n",
    "                'reason': kwargs.get('force_stop_reason', 'unknown'),\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            })\n",
    "\n",
    "        # Track tool usage\n",
    "        if \"current_tool_use\" in kwargs and kwargs[\"current_tool_use\"].get(\"name\"):\n",
    "            tool_name = kwargs[\"current_tool_use\"][\"name\"]\n",
    "            print(f\"ðŸ”§ Using tool: {tool_name}\")\n",
    "            execution_metrics['tool_usage'][tool_name] = execution_metrics['tool_usage'].get(tool_name, 0) + 1\n",
    "\n",
    "        # Show metrics when data is available\n",
    "        #if \"data\" in kwargs:\n",
    "            # Only show first 20 chars of each chunk for demo purposes\n",
    "            #data_snippet = kwargs[\"data\"][:20] + (\"...\" if len(kwargs[\"data\"]) > 20 else \"\")\n",
    "            #print(f\"ðŸ“Ÿ Text: {data_snippet}\")   \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error in event loop tracker: {e}\"\n",
    "        print(f\"âŒ {error_msg}\")\n",
    "        execution_metrics['errors'].append({\n",
    "            'type': 'event_loop_tracker_error',\n",
    "            'message': str(e),\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        })\n",
    "    \n",
    "def agent_description_composer(agent_config):\n",
    "    \"\"\"Compose the agent description\"\"\"\n",
    "    return f\"\"\"\n",
    "    Role: {agent_config.get(\"role\", None)}\n",
    "    Goal: {agent_config.get(\"goal\", None)}\n",
    "    Backstory: {agent_config.get(\"backstory\", None)}\n",
    "    \"\"\"\n",
    "\n",
    "def create_agent_with_model(agent_config, model_config, **kwargs):\n",
    "    \"\"\"Create an agent with specific model configuration\"\"\"\n",
    "    llm = BedrockModel(\n",
    "        model_id=model_config[\"model_id\"].split(\"/\")[-1],\n",
    "        temperature=model_config.get(\"model_kwargs\").get(\"temperature\", 0.6),\n",
    "        top_p=model_config.get(\"model_kwargs\").get(\"top_p\", 0.9),\n",
    "        max_tokens=model_config.get(\"model_kwargs\").get(\"max_tokens\", 4000)\n",
    "    )\n",
    "\n",
    "    args = {}\n",
    "    args[\"model\"]=llm\n",
    "    args[\"system_prompt\"]=agent_config.get(\"prompt\", None)\n",
    "    args[\"name\"]=agent_config.get(\"name\", None)\n",
    "    args[\"description\"]=agent_description_composer(agent_config)\n",
    "    args[\"callback_handler\"]=event_loop_tracker\n",
    "    \n",
    "    if not agent_config.get(\"verbose\",True):\n",
    "        args[\"callback_handler\"]=None\n",
    "    \n",
    "    return Agent(**args)\n",
    "\n",
    "def print_agent_info(agent, model_config) -> None:\n",
    "    \"\"\"Print agent creation information.\"\"\"\n",
    "    print(\n",
    "        f\"Created agent: {agent.name}\\n\"\n",
    "        f\"Agent Description: {agent.description}\\n\"\n",
    "        f\"Using model: {agent.model.get_config()}\"\n",
    "    )\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#agent_name = \"Culinary Coordinator\"\n",
    "agent_config = agents_config[\"Culinary Coordinator\"]\n",
    "agent_type=agent_config[\"name\"]\n",
    "model_config = select_model_for_complexity(strand_config[\"model_assignment\"][\"agent_model_mapping\"][agent_type], integration_config)\n",
    "culinary_coordinator_agent = create_agent_with_model(agent_config, model_config)\n",
    "print_agent_info(culinary_coordinator_agent, model_config)\n",
    "\n",
    "agent_name = \"Ingredient Substitution Expert\"\n",
    "agent_config = agents_config[\"Ingredient Substitution Expert\"]\n",
    "agent_type=agent_config[\"name\"]\n",
    "model_config = select_model_for_complexity(strand_config[\"model_assignment\"][\"agent_model_mapping\"][agent_type], integration_config)\n",
    "ingredient_substitution_expert_agent = create_agent_with_model(agent_config, model_config)\n",
    "print_agent_info(ingredient_substitution_expert_agent, model_config)\n",
    "\n",
    "agent_name = \"Culinary Experience Optimizer\"\n",
    "agent_config = agents_config[\"Culinary Experience Optimizer\"]\n",
    "agent_type=agent_config[\"name\"]\n",
    "model_config = select_model_for_complexity(strand_config[\"model_assignment\"][\"agent_model_mapping\"][agent_type], integration_config)\n",
    "culinary_experience_optimizer_agent = create_agent_with_model(agent_config, model_config)\n",
    "print_agent_info(culinary_experience_optimizer_agent, model_config)\n",
    "\n",
    "agent_name = \"Quality Assurance Chef\"\n",
    "agent_config = agents_config[\"Quality Assurance Chef\"]\n",
    "agent_type=agent_config[\"name\"]\n",
    "model_config = select_model_for_complexity(strand_config[\"model_assignment\"][\"agent_model_mapping\"][agent_type], integration_config)\n",
    "quality_assurance_chef_agent = create_agent_with_model(agent_config, model_config)\n",
    "print_agent_info(quality_assurance_chef_agent, model_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example recipe for analysis\n",
    "recipe_request = {\n",
    "    \"food_name\": \"Canelones de ternera XXL al Pedro Ximenez\",\n",
    "    \"servings\": 4,\n",
    "    \"intolerances\": [\n",
    "        \"Milk\",\n",
    "        \"Eggs\",\n",
    "        \"Beef\",\n",
    "        \"Corn\",\n",
    "        \"Gluten\",\n",
    "        \"Rice\",\n",
    "        \"Garlic\"\n",
    "    ],\n",
    "    \"exclusions\": [\"Pepper\"],\n",
    "    \"preferences\": [\"kosher\"],\n",
    "    \"output_language\": \"spanish\",\n",
    "    \"country\": \"Spain\"\n",
    "}\n",
    "initial_recipe={}\n",
    "initial_recipe[\"food_name\"]=recipe_request.pop(\"food_name\")\n",
    "initial_recipe[\"country\"]=recipe_request[\"country\"]\n",
    "initial_recipe[\"output_language\"]=recipe_request[\"output_language\"]\n",
    "initial_recipe[\"servings\"]=recipe_request[\"servings\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Support functions\n",
    "\n",
    "def variable_injection(task:dict, recipe_context:dict):\n",
    "    try:\n",
    "        prompt = PromptTemplate(name=task.get(\"name\"), template=f'''{task.get(\"description\")}''').to_string(**recipe_context)\n",
    "    except MissingTemplateValuesError as e:\n",
    "        print(f\"Missing values: {e.missing_values}\")  # {'name'}\n",
    "    except InvalidTemplateKeysError as e:\n",
    "        print(f\"Invalid keys: {e.invalid_keys}\")  # {'name'}\n",
    "    except TemplateSerializationError as e:\n",
    "        print(f\"Serialization error: {e.message}\")  # 'Invalid template string'\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")  # 'Unexpected error'\n",
    "    return prompt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential workflow processing\n",
    "tasks = {\n",
    "    \"initial_recipe_analysis\": {\n",
    "        \"description\": f'''{variable_injection(tasks_config['Initial Recipe Analysis'], initial_recipe)}''',\n",
    "        \"status\": \"pending\",\n",
    "        \"agent\": culinary_coordinator_agent,\n",
    "        \"dependencies\": []\n",
    "    },\n",
    "    \"ingredient_substitution_strategy\": {\n",
    "        \"description\": f'''{variable_injection(tasks_config['Ingredient Substitution Strategy'], recipe_request)}''',\n",
    "        \"status\": \"pending\",\n",
    "        \"agent\": ingredient_substitution_expert_agent,\n",
    "        \"dependencies\": [\"initial_recipe_analysis\"]\n",
    "    },\n",
    "    \"culinary_experience_enhancement\": {\n",
    "        \"description\": f'''{variable_injection(tasks_config['Culinary Experience Enhancement'], recipe_request)}''',\n",
    "        \"status\": \"pending\",\n",
    "        \"agent\": culinary_experience_optimizer_agent,\n",
    "        \"dependencies\": [\"ingredient_substitution_strategy\"]\n",
    "    },\n",
    "    \"final_quality_assurance\": {\n",
    "        \"description\": f'''{variable_injection(tasks_config['Final Quality Assurance'], recipe_request)}''',\n",
    "        \"status\": \"pending\",\n",
    "        \"agent\": quality_assurance_chef_agent,\n",
    "        \"dependencies\": [\"culinary_experience_enhancement\"]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sequential workflow processing\n",
    "def weCookio_process_workflow(tasks:dict):\n",
    "    print(f''' Flow:\\n {tasks} \\n ''')\n",
    "    context = ''\n",
    "    for task in tasks:\n",
    "        if tasks[task]['dependencies']:\n",
    "            print(f'''\\nInjecting dependency: {tasks[task]['dependencies']}''')\n",
    "            task_result = tasks[task]['agent'](f'''Previous task results:{context}\\n\\n Task: \\n {tasks[task]['description']}''')\n",
    "        else:\n",
    "            print(f'''Injecting task: {tasks[task]['description']}\\n''')\n",
    "            task_result = tasks[task]['agent'](f'''Task: \\n {tasks[task]['description']}''')\n",
    "        tasks[task]['result'] = task_result\n",
    "        context = task_result\n",
    "        print (context)\n",
    "    return tasks        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    result = weCookio_process_workflow(tasks=tasks)\n",
    "except Exception as e:\n",
    "    print(f\"Error running Workflow: {e}\")\n",
    "    print(\"Make sure you have AWS credentials configured and the required permissions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "#pprint(\"\".join(result['initial_recipe_analysis']['result'].message['content'][0]['text']))\n",
    "print(\"\".join(result['final_quality_assurance']['result'].message['content'][0]['text']))\n",
    "print(f'''\\n\\n Aggregated Metrics: \\n\\n''')\n",
    "pprint(result['final_quality_assurance']['result'].metrics)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agi-frameworks-poc (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
